{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c9eff21",
   "metadata": {
    "id": "zAXHC6-Tn2O5",
    "papermill": {
     "duration": 0.003998,
     "end_time": "2023-05-26T00:44:33.995386",
     "exception": false,
     "start_time": "2023-05-26T00:44:33.991388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc37f4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T00:44:34.003857Z",
     "iopub.status.busy": "2023-05-26T00:44:34.003004Z",
     "iopub.status.idle": "2023-05-26T00:44:35.207214Z",
     "shell.execute_reply": "2023-05-26T00:44:35.206169Z"
    },
    "papermill": {
     "duration": 1.211485,
     "end_time": "2023-05-26T00:44:35.210043",
     "exception": false,
     "start_time": "2023-05-26T00:44:33.998558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import jo_wilder\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31a06945",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T00:44:35.218221Z",
     "iopub.status.busy": "2023-05-26T00:44:35.217200Z",
     "iopub.status.idle": "2023-05-26T00:44:37.255099Z",
     "shell.execute_reply": "2023-05-26T00:44:37.254055Z"
    },
    "papermill": {
     "duration": 2.045062,
     "end_time": "2023-05-26T00:44:37.258132",
     "exception": false,
     "start_time": "2023-05-26T00:44:35.213070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "model_folder = '/kaggle/input/reverting-restart'\n",
    "\n",
    "models = {}\n",
    "\n",
    "for file in os.listdir(model_folder):\n",
    "    \n",
    "    if 'question' in file:\n",
    "        x = int(file.split('_')[1])\n",
    "        \n",
    "        with open(f'{model_folder}/{file}', 'rb') as file:\n",
    "            model_ = pickle.load(file)\n",
    "        \n",
    "        models[f'question_{x}'] = model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d6a84d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T00:44:37.268940Z",
     "iopub.status.busy": "2023-05-26T00:44:37.266854Z",
     "iopub.status.idle": "2023-05-26T00:44:37.275344Z",
     "shell.execute_reply": "2023-05-26T00:44:37.274472Z"
    },
    "papermill": {
     "duration": 0.016433,
     "end_time": "2023-05-26T00:44:37.277925",
     "exception": false,
     "start_time": "2023-05-26T00:44:37.261492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def prep_data(df=None):\n",
    "#     \"prepping the data for the submission\"\n",
    "    \n",
    "#     level_dict = {\n",
    "#         '0-4' : [1, 2, 3],\n",
    "#         '5-12' : [4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    "#         '13-22' : [14, 15, 16, 17, 18]\n",
    "#     }\n",
    "\n",
    "    \n",
    "#     df_ = df.copy()\n",
    "    \n",
    "#     # getting elapsed diffs\n",
    "#     df_['event_time_delta'] = (\n",
    "#         df_\n",
    "#         .groupby('session_id')['elapsed_time']\n",
    "#         .transform(lambda x: x.diff().fillna(0))\n",
    "#     )\n",
    "\n",
    "#     # getting the time until the next event\n",
    "#     df_['time_delta_til_next'] = (\n",
    "#         df_\n",
    "#         .groupby('session_id')['elapsed_time']\n",
    "#         .transform(lambda x: abs(x.diff(-1)).fillna(0)))\n",
    "    \n",
    "    \n",
    "#     # time delta means    \n",
    "#     time_delta_mean = df_.groupby('session_id').agg(event_time_mean=('event_time_delta', 'mean'),\n",
    "#                                                     event_time_std=('event_time_delta', 'std'),\n",
    "#                                                     event_time_max=('event_time_delta', 'max'))\n",
    "    \n",
    "#     # total time on each event\n",
    "#     total_time_event = (\n",
    "#         df_\n",
    "#         .groupby(['session_id', 'event_name'])\n",
    "#         .agg(total_time=('time_delta_til_next', 'sum'))\n",
    "#         .unstack()\n",
    "#     )   \n",
    "    \n",
    "#     # unique text ids\n",
    "#     nunique_text_ids = df_.groupby('session_id')['text_fqid'].nunique()\n",
    "    \n",
    "#     # unique fqids \n",
    "#     nunique_fqid = df_.groupby('session_id')['fqid'].nunique()\n",
    "    \n",
    "#     # how many events of each type occurred in the session\n",
    "#     event_counts = df_.groupby('session_id')['event_name'].value_counts().unstack()\n",
    "    \n",
    "#     # getting session lengths\n",
    "#     session_lengths = df_.groupby('session_id')['elapsed_time'].max().rename('total_length')\n",
    "    \n",
    "#     # total events in the session\n",
    "#     session_events = df_.groupby('session_id')['session_id'].count()\n",
    "    \n",
    "#     # final df pre labels\n",
    "#     df_features = (\n",
    "#         pd.concat([total_time_event, nunique_text_ids, nunique_fqid, event_counts, session_lengths, session_events, time_delta_mean], axis=1)\n",
    "#         .fillna(0)\n",
    "#         .drop(columns='session_id')\n",
    "#         .reset_index()\n",
    "#     )\n",
    "\n",
    "    \n",
    "#     return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d28897a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T00:44:37.286992Z",
     "iopub.status.busy": "2023-05-26T00:44:37.286041Z",
     "iopub.status.idle": "2023-05-26T00:44:37.301636Z",
     "shell.execute_reply": "2023-05-26T00:44:37.300666Z"
    },
    "papermill": {
     "duration": 0.022802,
     "end_time": "2023-05-26T00:44:37.304212",
     "exception": false,
     "start_time": "2023-05-26T00:44:37.281410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kaggle_prep(test_data=None):\n",
    "    \"how to prep the data for the kaggle notebook\"\n",
    "    \n",
    "    level_dict = {\n",
    "        '0-4' : [1, 2, 3],\n",
    "        '5-12' : [4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    "        '13-22' : [14, 15, 16, 17, 18]\n",
    "    }\n",
    "\n",
    "    \n",
    "    df_ = test_data.copy()\n",
    "        # getting elapsed diffs\n",
    "    df_['event_time_delta'] = (\n",
    "        df_\n",
    "        .groupby('session_id')['elapsed_time']\n",
    "        .transform(lambda x: x.diff().fillna(0))\n",
    "    )\n",
    "\n",
    "    # getting the time until the next event\n",
    "    df_['time_delta_til_next'] = (\n",
    "        df_\n",
    "        .groupby('session_id')['elapsed_time']\n",
    "        .transform(lambda x: abs(x.diff(-1)).fillna(0)))\n",
    "    \n",
    "    \n",
    "    # time delta means    \n",
    "    time_delta_mean = df_.groupby('session_id').agg(event_time_mean=('event_time_delta', 'mean'),\n",
    "                                                    event_time_std=('event_time_delta', 'std'),\n",
    "                                                    event_time_max=('event_time_delta', 'max'))\n",
    "    \n",
    "    # hover duration stats\n",
    "    hover_duration = df_.groupby('session_id').agg(hover_duration_mean=('hover_duration', 'mean'),\n",
    "                                                        hover_duration_std=('hover_duration', 'std'),\n",
    "                                                        hover_duration_max=('hover_duration', 'max'))\n",
    "    \n",
    "    # total time on each event\n",
    "    total_time_event = (\n",
    "        df_\n",
    "        .groupby(['session_id', 'event_name'])\n",
    "        .agg(total_time_event=('time_delta_til_next', 'sum'),\n",
    "             mean_time_event=('time_delta_til_next', 'mean'),\n",
    "             std_time_event=('time_delta_til_next', 'std'))\n",
    "        .unstack()\n",
    "    )\n",
    "    \n",
    "    # total time on each level    \n",
    "    level_duration = (\n",
    "        df_\n",
    "        .groupby(['session_id', 'level'])['elapsed_time']\n",
    "        .apply(lambda x: x.max() - x.min())\n",
    "        .unstack()\n",
    "        .rename(columns=lambda x: f'time_on_level_{x}')\n",
    "    )\n",
    "    \n",
    "    # unique text ids\n",
    "    nunique_text_ids = df_.groupby('session_id')['text_fqid'].nunique()\n",
    "    \n",
    "    # unique fqids \n",
    "    nunique_fqid = df_.groupby('session_id')['fqid'].nunique()\n",
    "    \n",
    "    # how many events of each type occurred in the session\n",
    "    event_counts = df_.groupby('session_id')['event_name'].value_counts().unstack()\n",
    "    \n",
    "    # getting session lengths\n",
    "    session_lengths = df_.groupby('session_id')['elapsed_time'].max().rename('total_length')\n",
    "    \n",
    "    # total events in the session\n",
    "    session_events = df_.groupby('session_id')['session_id'].count()\n",
    "    \n",
    "    # final df pre labels\n",
    "    df_features = (\n",
    "        pd.concat([total_time_event, nunique_text_ids, nunique_fqid, event_counts, \n",
    "                   session_lengths, session_events, time_delta_mean, hover_duration,\n",
    "                   level_duration], axis=1)\n",
    "        .fillna(0)\n",
    "        .drop(columns='session_id')\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    # fixing column names \n",
    "    df_features.rename(columns=lambda x: '_'.join(x) if isinstance(x, tuple) else x, inplace=True)\n",
    "    \n",
    "    return df_features.set_index('session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24e91f3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T00:44:37.312619Z",
     "iopub.status.busy": "2023-05-26T00:44:37.311865Z",
     "iopub.status.idle": "2023-05-26T00:44:37.316882Z",
     "shell.execute_reply": "2023-05-26T00:44:37.315931Z"
    },
    "papermill": {
     "duration": 0.01187,
     "end_time": "2023-05-26T00:44:37.319314",
     "exception": false,
     "start_time": "2023-05-26T00:44:37.307444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = jo_wilder.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef78115b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T00:44:37.328282Z",
     "iopub.status.busy": "2023-05-26T00:44:37.327220Z",
     "iopub.status.idle": "2023-05-26T00:44:37.931962Z",
     "shell.execute_reply": "2023-05-26T00:44:37.930856Z"
    },
    "papermill": {
     "duration": 0.612113,
     "end_time": "2023-05-26T00:44:37.934585",
     "exception": false,
     "start_time": "2023-05-26T00:44:37.322472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "limits = {'0-4':(1,4), '5-12':(4,14), '13-22':(14,19)}\n",
    "\n",
    "for test, sample_submission in iter_test:\n",
    "    \n",
    "    level_group = test['level_group'].values[0]\n",
    "    df_ = kaggle_prep(test_data=test)\n",
    "     \n",
    "    if level_group == '0-4':\n",
    "        feature_cols = models['question_1'].feature_name_\n",
    "    elif level_group == '5-12':\n",
    "        feature_cols = models['question_6'].feature_name_\n",
    "    else:\n",
    "        feature_cols = models['question_17'].feature_name_\n",
    "    \n",
    "    # figure out if feature columns are missing - important for submission\n",
    "    missing_columns = list(set(feature_cols) - set(df_.columns))\n",
    "    \n",
    "    # create a dataframe with the missing columns filled with 0s (for now)\n",
    "    missing_df = pd.DataFrame(0, columns=missing_columns, index=df_.index)\n",
    "    \n",
    "    # combine the original df and the missing df\n",
    "    df_ = pd.concat([df_, missing_df], axis=1)\n",
    "    \n",
    "    a, b = limits[level_group]\n",
    "    \n",
    "    for question in range(a, b):\n",
    "        model_ = models[f'question_{question}']\n",
    "        threshold = 0.63\n",
    "        feature_cols = model_.feature_name_\n",
    "\n",
    "        preds = model_.predict_proba(df_[feature_cols])[0, 1]\n",
    "        fixed_preds = (preds > threshold).astype(int)\n",
    "\n",
    "        mask = sample_submission.session_id.str.contains(f'q{question}')\n",
    "        sample_submission.loc[mask, 'correct'] = fixed_preds\n",
    "\n",
    "    env.predict(sample_submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15.949294,
   "end_time": "2023-05-26T00:44:38.762337",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-26T00:44:22.813043",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

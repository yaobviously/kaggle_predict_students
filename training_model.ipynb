{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GroupKFold\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca45c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the train labels\n",
    "\n",
    "labels_df = pd.read_csv('train_labels.csv')\n",
    "\n",
    "labels_df['session'] = labels_df['session_id'].apply(lambda x: int(x.split('_')[0]))\n",
    "labels_df['question'] = labels_df['session_id'].apply(lambda x: int(x.split('q')[1]))\n",
    "\n",
    "labels_df = (\n",
    "    labels_df\n",
    "    .sort_values(by=['session', 'question'], ascending=[True, True])\n",
    "    .reindex(columns=['session_id', 'session', 'question', 'correct'])\n",
    "    .reset_index(drop=True)\n",
    "    .drop(columns='session_id')\n",
    ")\n",
    "\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5df2174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding cols to save memory\n",
    "exclude_cols = ['index', 'fullscreen', 'hq', 'music', 'text']\n",
    "\n",
    "# borrowing the dtypes dictionary from a featured notebook\n",
    "dtypes = {\n",
    "    'elapsed_time':np.int32,\n",
    "    'event_name':'category',\n",
    "    'name':'category',\n",
    "    'level':np.uint8,\n",
    "    'room_coor_x':np.float32,\n",
    "    'room_coor_y':np.float32,\n",
    "    'screen_coor_x':np.float32,\n",
    "    'screen_coor_y':np.float32,\n",
    "    'hover_duration':np.float32,\n",
    "    'text': 'category',\n",
    "    'fqid': 'category',\n",
    "    'room_fqid':'category',\n",
    "    'text_fqid':'category',\n",
    "    'fullscreen': bool,\n",
    "    'hq':bool,\n",
    "    'music': bool,\n",
    "    'level_group':'category'\n",
    "}\n",
    "\n",
    "df = pd.read_csv('train.csv', usecols=lambda x: x not in exclude_cols, dtype=dtypes)\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .sort_values(by=['session_id', 'level', 'elapsed_time'], ascending=[True, True, True])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "# getting elapsed diffs\n",
    "df['event_time_delta'] = (\n",
    "    df\n",
    "    .groupby('session_id')['elapsed_time']\n",
    "    .transform(lambda x: x.diff().fillna(x.min()))\n",
    ")\n",
    "\n",
    "# getting the time until the next event\n",
    "df['time_delta_til_next'] = (\n",
    "    df\n",
    "    .groupby('session_id')['elapsed_time']\n",
    "    .transform(lambda x: abs(x.diff(-1)).fillna(abs(x.min())))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5413fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_last_4(x):\n",
    "#     return x.iloc[-4:]\n",
    "\n",
    "\n",
    "# # get last 4 fqid\n",
    "# fqid_df = df.groupby(['session_id', 'level_group'])['fqid'].apply(get_last_4).reset_index()\n",
    "# fqid_df['entry_number'] = fqid_df.groupby(['session_id', 'level_group']).cumcount() + 1\n",
    "\n",
    "# final_fqid = (\n",
    "#     fqid_df\n",
    "#     .pivot(index=['session_id', 'level_group'],\n",
    "#            columns='entry_number',\n",
    "#            values='fqid')\n",
    "#     .rename(columns={1:'fqid_1back', 2:'fqid_2back', 3:'fqid_3back', 4:'fqid_4back'})\n",
    "# )\n",
    "\n",
    "# final_fqid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a747973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_level(level_group=None, labels_df=labels_df):\n",
    "    \"gets group-level data to train models for each question\"\n",
    "    \n",
    "    level_dict = {\n",
    "        '0-4' : [1, 2, 3],\n",
    "        '5-12' : [4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    "        '13-22' : [14, 15, 16, 17, 18]\n",
    "    }\n",
    "\n",
    "    \n",
    "    df_ = df[df['level_group'] == level_group].copy()\n",
    "    \n",
    "    # getting elapsed diffs\n",
    "    df_['event_time_delta'] = (\n",
    "        df_\n",
    "        .groupby('session_id')['elapsed_time']\n",
    "        .transform(lambda x: x.diff().fillna(x.min()))\n",
    "    )\n",
    "\n",
    "    # getting the time until the next event\n",
    "    df_['time_delta_til_next'] = (\n",
    "        df_\n",
    "        .groupby('session_id')['elapsed_time']\n",
    "        .transform(lambda x: abs(x.diff(-1)).fillna(abs(x.min())))\n",
    "    )\n",
    "    \n",
    "    # time delta means    \n",
    "    time_delta_mean = df_.groupby('session_id').agg(event_time_mean=('event_time_delta', 'mean'),\n",
    "                                                    event_time_std=('event_time_delta', 'std'),\n",
    "                                                    event_time_max=('event_time_delta', 'max'))\n",
    "    \n",
    "    # total time on each event\n",
    "    total_time_event = (\n",
    "        df_\n",
    "        .groupby(['session_id', 'event_name'])\n",
    "        .agg(total_time=('time_delta_til_next', 'sum'))\n",
    "        .unstack()\n",
    "    )   \n",
    "    \n",
    "    # unique text ids\n",
    "    nunique_text_ids = df_.groupby('session_id')['text_fqid'].nunique()\n",
    "    \n",
    "    # unique fqids \n",
    "    nunique_fqid = df_.groupby('session_id')['fqid'].nunique()\n",
    "    \n",
    "    # how many events of each type occurred in the session\n",
    "    event_counts = df_.groupby('session_id')['event_name'].value_counts().unstack()\n",
    "    \n",
    "    # getting session lengths\n",
    "    session_lengths = df_.groupby('session_id')['elapsed_time'].max().rename('total_length')\n",
    "    \n",
    "    # total events in the session\n",
    "    session_events = df_.groupby('session_id')['session_id'].count()\n",
    "    \n",
    "    # getting labels\n",
    "    session_labels = (\n",
    "        labels_df\n",
    "        .loc[labels_df.question.isin(level_dict[level_group])]\n",
    "        .pivot(columns='question', values='correct', index='session')\n",
    "    )\n",
    "    \n",
    "    # final df pre labels\n",
    "    df_features = (\n",
    "        pd.concat([total_time_event, nunique_text_ids, nunique_fqid, event_counts, session_lengths, session_events, time_delta_mean], axis=1)\n",
    "    )\n",
    "    \n",
    "    # df with labels\n",
    "    df_final = (\n",
    "        pd.concat([df_features, session_labels], axis=1)\n",
    "        .reset_index()\n",
    "        .drop(columns=['session_id'])\n",
    "        .rename(columns={'index' : 'session_id'})\n",
    "    )\n",
    "    \n",
    "    # extracting date and time data from the session_id\n",
    "    df_final['year'] = df_final['session_id'].apply(lambda x: int(str(x)[:2]))\n",
    "    df_final['month'] = df_final['session_id'].apply(lambda x: int(str(x)[2:4]))\n",
    "    df_final['day'] = df_final['session_id'].apply(lambda x: int(str(x)[4:6]))\n",
    "    df_final['hour'] = df_final['session_id'].apply(lambda x: int(str(x)[6:8]))\n",
    "\n",
    "    # creating a weekend indicator because weekends are different\n",
    "    df_final['weekend'] = np.where(df_final['day'].isin([6,0]), 1, 0)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c902f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a simple example to know what i'm doing\n",
    "group_k_fold = GroupKFold(n_splits=5)\n",
    "\n",
    "group1_data = get_data_for_level('5-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c528ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns that routinely added zero or negative value in prelim tests\n",
    "bad_cols = ['year', 'checkpoint', 'session_id', 'hour', 'day', \n",
    "            'weekend', 'fqid', 'notification_click', 'month', \n",
    "            'cutscene_click', 'observation_click']\n",
    "\n",
    "level_dict = {\n",
    "    '0-4' : [1, 2, 3],\n",
    "    '5-12' : [4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    "    '13-22' : [14, 15, 16, 17, 18]\n",
    "}\n",
    "\n",
    "# standardized feature columns to simplify\n",
    "feature_cols = [x for x in group1_data.columns if x not in level_dict['5-12']]\n",
    "feature_cols = [x for x in feature_cols if x not in bad_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354b145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a df of the best params \n",
    "\n",
    "best_params_df = pd.DataFrame()\n",
    "\n",
    "for question in range(1, 19):\n",
    "    \n",
    "    if question in [1, 2, 3]:\n",
    "        df_ = get_data_for_level('0-4')\n",
    "    elif question in [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]:\n",
    "        df_ = get_data_for_level('5-12')\n",
    "    else:\n",
    "        df_ = get_data_for_level('13-22')\n",
    "    \n",
    "    fold = 1\n",
    "    \n",
    "    model = XGBClassifier(n_estimators=25)\n",
    "    cv_method = GroupKFold(n_splits=5)\n",
    "    \n",
    "    grid_params_ = {\n",
    "        'max_depth' : [5, 6],\n",
    "        'min_child_weight' : [3, 6, 25]\n",
    "    }\n",
    "    \n",
    "    X = df_[feature_cols]\n",
    "    X_groups = df_['session_id'].values\n",
    "    y = labels_df.loc[labels_df['question'] == question].set_index('session').loc[X_groups]['correct']\n",
    "    \n",
    "    \n",
    "    gridsearch = GridSearchCV(model,\n",
    "                              param_grid=grid_params,\n",
    "                              cv=cv_method.split(X, y, groups=X_groups),\n",
    "                              scoring='f1_macro')    \n",
    "    gridsearch.fit(X, y)\n",
    "    \n",
    "    best_depth = gridsearch.best_params_['max_depth']\n",
    "    best_weight = gridsearch.best_params_['min_child_weight']\n",
    "    best_score = gridsearch.best_score_\n",
    "    \n",
    "    param_score_df_ = pd.DataFrame({\n",
    "        'question' : question,\n",
    "        'best_depth' : best_depth,\n",
    "        'best_weight' : best_weight,\n",
    "        'best_score' : best_score},\n",
    "        index=[0]\n",
    "    )\n",
    "    \n",
    "    best_params_df = pd.concat([best_params_df, param_score_df_])\n",
    "    print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f150fe56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>best_depth</th>\n",
       "      <th>best_weight</th>\n",
       "      <th>best_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>0.588425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.502613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.498391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.626601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.664981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question  best_depth  best_weight  best_score\n",
       "0         1           5           25    0.588425\n",
       "0         2           5            3    0.502613\n",
       "0         3           5            3    0.498391\n",
       "0         4           5            6    0.626601\n",
       "0         5           5            6    0.664981"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f51a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "vals = []\n",
    "final_preds = []\n",
    "\n",
    "for question in range(1, 19):\n",
    "    \n",
    "    if question in [1, 2, 3]:\n",
    "        df_ = get_data_for_level('0-4')\n",
    "    elif question in [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]:\n",
    "        df_ = get_data_for_level('5-12')\n",
    "    else:\n",
    "        df_ = get_data_for_level('13-22')\n",
    "    \n",
    "    fold = 1\n",
    "    \n",
    "    for train, val in group_k_fold.split(X=df_, groups=df_['session_id']):\n",
    "\n",
    "        train_x = df_.iloc[train].copy()\n",
    "        train_sessions = train_x['session_id'].values\n",
    "        train_x = train_x[feature_cols].copy()\n",
    "        train_y = labels_df.loc[labels_df['question'] == question].set_index('session').loc[train_sessions]['correct']\n",
    "        \n",
    "        val_x = df_.iloc[val].copy()\n",
    "        val_sessions = val_x['session_id'].values\n",
    "        val_x = val_x[feature_cols]\n",
    "        val_y = labels_df.loc[labels_df['question'] == question].set_index('session').loc[val_sessions]['correct']\n",
    "\n",
    "        model = XGBClassifier(n_estimators=50)        \n",
    "        model.fit(train_x, train_y)\n",
    "        \n",
    "        preds = model.predict(val_x)\n",
    "        f1_score_ = f1_score(val_y, preds, average='macro')\n",
    "        \n",
    "        val_probs = model.predict_proba(val_x)[:,1]\n",
    "\n",
    "        best_threshold = None\n",
    "        best_f1 = 0.0\n",
    "\n",
    "        for threshold in np.arange(0.25, 0.88, 0.03):  \n",
    "            \n",
    "            # apply the threshold\n",
    "            val_preds = (val_probs > threshold).astype(int)\n",
    "\n",
    "            # get f1 score\n",
    "            f1 = f1_score(val_y, val_preds, average='macro')\n",
    "\n",
    "            # is it best? if so, change best\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        final_preds_ = (val_probs > best_threshold).astype(int)\n",
    "        \n",
    "        if fold == 4:\n",
    "            vals.append(val_y)\n",
    "            final_preds.append(final_preds_)            \n",
    "        \n",
    "        result_df_ = (pd.DataFrame(\n",
    "            {'question' : question,\n",
    "             'fold' : fold,\n",
    "             'default_f1': f1_score_,\n",
    "             'best_f1' : best_f1, \n",
    "             'best_threshold' : best_threshold},\n",
    "             index=[0]\n",
    "        )\n",
    "                    )\n",
    "                     \n",
    "        result_df = pd.concat([result_df, result_df_])\n",
    "        \n",
    "        print(\"Best Threshold:\", best_threshold)\n",
    "        print(\"Best F1 Score:\", best_f1)\n",
    "        \n",
    "        if fold == 4:\n",
    "            models[question] = [model, best_threshold]\n",
    "        \n",
    "        print(question, fold, f1_score_)\n",
    "        fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2a5ce682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>fold</th>\n",
       "      <th>default_f1</th>\n",
       "      <th>best_f1</th>\n",
       "      <th>best_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.604881</td>\n",
       "      <td>0.653837</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.604294</td>\n",
       "      <td>0.623697</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.591507</td>\n",
       "      <td>0.640093</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.584502</td>\n",
       "      <td>0.631600</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.612723</td>\n",
       "      <td>0.650127</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question  fold  default_f1   best_f1  best_threshold\n",
       "0         1     1    0.604881  0.653837            0.67\n",
       "0         1     2    0.604294  0.623697            0.61\n",
       "0         1     3    0.591507  0.640093            0.64\n",
       "0         1     4    0.584502  0.631600            0.67\n",
       "0         1     5    0.612723  0.650127            0.61"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df=None):\n",
    "    \"how to prep the data for the kaggle notebook\"\n",
    "    \n",
    "    level_dict = {\n",
    "        '0-4' : [1, 2, 3],\n",
    "        '5-12' : [4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    "        '13-22' : [14, 15, 16, 17, 18]\n",
    "    }\n",
    "\n",
    "    \n",
    "    df_ = df.copy()\n",
    "    \n",
    "    # getting elapsed diffs\n",
    "    df_['event_time_delta'] = (\n",
    "        df_\n",
    "        .groupby('session_id')['elapsed_time']\n",
    "        .transform(lambda x: x.diff().fillna(x.min()))\n",
    "    )\n",
    "\n",
    "    # getting the time until the next event\n",
    "    df_['time_delta_til_next'] = (\n",
    "        df_\n",
    "        .groupby('session_id')['elapsed_time']\n",
    "        .transform(lambda x: abs(x.diff(-1)).fillna(abs(x.min())))\n",
    "    )\n",
    "    \n",
    "    # time delta means    \n",
    "    time_delta_mean = df_.groupby('session_id').agg(event_time_mean=('event_time_delta', 'mean'),\n",
    "                                                    event_time_std=('event_time_delta', 'std'),\n",
    "                                                    event_time_max=('event_time_delta', 'max'))\n",
    "    \n",
    "    # total time on each event\n",
    "    total_time_event = (\n",
    "        df_\n",
    "        .groupby(['session_id', 'event_name'])\n",
    "        .agg(total_time=('time_delta_til_next', 'sum'))\n",
    "        .unstack()\n",
    "    )   \n",
    "    \n",
    "    # unique text ids\n",
    "    nunique_text_ids = df_.groupby('session_id')['text_fqid'].nunique()\n",
    "    \n",
    "    # unique fqids \n",
    "    nunique_fqid = df_.groupby('session_id')['fqid'].nunique()\n",
    "    \n",
    "    # how many events of each type occurred in the session\n",
    "    event_counts = df_.groupby('session_id')['event_name'].value_counts().unstack()\n",
    "    \n",
    "    # getting session lengths\n",
    "    session_lengths = df_.groupby('session_id')['elapsed_time'].max().rename('total_length')\n",
    "    \n",
    "    # total events in the session\n",
    "    session_events = df_.groupby('session_id')['session_id'].count()\n",
    "    \n",
    "    # final df pre labels\n",
    "    df_features = (\n",
    "        pd.concat([total_time_event, nunique_text_ids, nunique_fqid, event_counts, session_lengths, session_events, time_delta_mean], axis=1)\n",
    "        .drop(columns='session_id')\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    df_features['year'] = df_features['session_id'].apply(lambda x: int(str(x)[:2]))\n",
    "    df_features['month'] = df_features['session_id'].apply(lambda x: int(str(x)[2:4]))\n",
    "    df_features['day'] = df_features['session_id'].apply(lambda x: int(str(x)[4:6]))\n",
    "    df_features['hour'] = df_features['session_id'].apply(lambda x: int(str(x)[6:8]))\n",
    "\n",
    "    # # creating a weekend indicator because weekends are different\n",
    "    df_features['weekend'] = np.where(df_features['day'].isin([6,0]), 1, 0)\n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving models\n",
    "for key in models.keys():\n",
    "    \n",
    "    model_ = models[key][0]\n",
    "    \n",
    "    with open(f'model_question_{key}.pickle', 'wb') as file:\n",
    "        pickle.dump(model_, file, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dae630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving thresholds - no reason to do this separately, TODO\n",
    "threshold_list = []\n",
    "\n",
    "for key in models.keys():\n",
    "    \n",
    "    threshold_ = models[key][1].round(2)\n",
    "    threshold_list.append(threshold_)\n",
    "    \n",
    "with open('threshold_list.pickle', 'wb') as file:\n",
    "    pickle.dump(threshold_list, file, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b3986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving features\n",
    "with open('feature_cols_may17.pickle', 'wb') as file:\n",
    "    pickle.dump(feature_cols, file, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e0450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell iterates over the test data \n",
    "\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# defining the questions for each group\n",
    "limits = {'0-4':(1,4), '5-12':(4,14), '13-22':(14,19)}\n",
    "\n",
    "for _, tf in test_df.groupby(['session_id', 'level_group']):\n",
    "    \n",
    "    # get the level group (to get the data for the model)\n",
    "    level_group = tf['level_group'].values[0]\n",
    "    # create feature df\n",
    "    df_ = prep_data(tf)\n",
    "    \n",
    "    # get the questions to iterate over\n",
    "    a, b = limits[level_group]  \n",
    "    \n",
    "    for question in range(a, b):\n",
    "        # getting model and threshold for the question\n",
    "        model_ = models[question][0]\n",
    "        threshold = models[question][1]\n",
    "        \n",
    "        raw_pred_proba = models_.predict_proba(df_[feature_cols])[:,1]\n",
    "        final_pred = (raw_pred_proba > threshold).astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GroupKFold\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca45c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the train labels\n",
    "\n",
    "labels_df = pd.read_csv('train_labels.csv')\n",
    "\n",
    "labels_df['session'] = labels_df['session_id'].apply(lambda x: int(x.split('_')[0]))\n",
    "labels_df['question'] = labels_df['session_id'].apply(lambda x: int(x.split('q')[1]))\n",
    "\n",
    "labels_df = (\n",
    "    labels_df\n",
    "    .sort_values(by=['session', 'question'], ascending=[True, True])\n",
    "    .reindex(columns=['session_id', 'session', 'question', 'correct'])\n",
    "    .reset_index(drop=True)\n",
    "    .drop(columns='session_id')\n",
    ")\n",
    "\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5df2174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding cols to save memory\n",
    "exclude_cols = ['index', 'fullscreen', 'hq', 'music', 'text']\n",
    "\n",
    "# borrowing the dtypes dictionary from a featured notebook\n",
    "dtypes = {\n",
    "    'elapsed_time':np.int32,\n",
    "    'event_name':'category',\n",
    "    'name':'category',\n",
    "    'level':np.uint8,\n",
    "    'room_coor_x':np.float32,\n",
    "    'room_coor_y':np.float32,\n",
    "    'screen_coor_x':np.float32,\n",
    "    'screen_coor_y':np.float32,\n",
    "    'hover_duration':np.float32,\n",
    "    'text': 'category',\n",
    "    'fqid': 'category',\n",
    "    'room_fqid':'category',\n",
    "    'text_fqid':'category',\n",
    "    'fullscreen': bool,\n",
    "    'hq':bool,\n",
    "    'music': bool,\n",
    "    'level_group':'category'\n",
    "}\n",
    "\n",
    "df = pd.read_csv('train.csv', usecols=lambda x: x not in exclude_cols, dtype=dtypes)\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .sort_values(by=['session_id', 'level', 'elapsed_time'], ascending=[True, True, True])\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5413fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i like this feature and the code to produce it, but it may not be useful\n",
    "# out for now\n",
    "# def get_last_4(x):\n",
    "#     return x.iloc[-4:]\n",
    "\n",
    "\n",
    "# # get last 4 fqid\n",
    "# fqid_df = df.groupby(['session_id', 'level_group'])['fqid'].apply(get_last_4).reset_index()\n",
    "# fqid_df['entry_number'] = fqid_df.groupby(['session_id', 'level_group']).cumcount() + 1\n",
    "\n",
    "# final_fqid = (\n",
    "#     fqid_df\n",
    "#     .pivot(index=['session_id', 'level_group'],\n",
    "#            columns='entry_number',\n",
    "#            values='fqid')\n",
    "#     .rename(columns={1:'fqid_1back', 2:'fqid_2back', 3:'fqid_3back', 4:'fqid_4back'})\n",
    "# )\n",
    "\n",
    "# final_fqid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a747973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_level(level_group=None, labels_df=labels_df):\n",
    "    \"gets group-level data to train models for each question\"\n",
    "    \n",
    "    level_dict = {\n",
    "        '0-4' : [1, 2, 3],\n",
    "        '5-12' : [4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    "        '13-22' : [14, 15, 16, 17, 18]\n",
    "    }\n",
    "\n",
    "    \n",
    "    df_ = df[df['level_group'] == level_group].copy()\n",
    "    \n",
    "    # getting elapsed diffs\n",
    "    df_['event_time_delta'] = (\n",
    "        df_\n",
    "        .groupby('session_id')['elapsed_time']\n",
    "        .transform(lambda x: x.diff().fillna(x.min()))\n",
    "    )\n",
    "\n",
    "    # getting the time until the next event\n",
    "    df_['time_delta_til_next'] = (\n",
    "        df_\n",
    "        .groupby('session_id')['elapsed_time']\n",
    "        .transform(lambda x: abs(x.diff(-1)).fillna(abs(x.min())))\n",
    "    )\n",
    "    \n",
    "    # time delta means    \n",
    "    time_delta_mean = df_.groupby('session_id').agg(event_time_mean=('event_time_delta', 'mean'),\n",
    "                                                    event_time_std=('event_time_delta', 'std'),\n",
    "                                                    event_time_max=('event_time_delta', 'max'))\n",
    "    \n",
    "    # total time on each event\n",
    "    total_time_event = (\n",
    "        df_\n",
    "        .groupby(['session_id', 'event_name'])\n",
    "        .agg(total_time=('time_delta_til_next', 'sum'))\n",
    "        .unstack()\n",
    "    )   \n",
    "    \n",
    "    # unique text ids\n",
    "    nunique_text_ids = df_.groupby('session_id')['text_fqid'].nunique()\n",
    "    \n",
    "    # unique fqids \n",
    "    nunique_fqid = df_.groupby('session_id')['fqid'].nunique()\n",
    "    \n",
    "    # how many events of each type occurred in the session\n",
    "    event_counts = df_.groupby('session_id')['event_name'].value_counts().unstack()\n",
    "    \n",
    "    # getting session lengths\n",
    "    session_lengths = df_.groupby('session_id')['elapsed_time'].max().rename('total_length')\n",
    "    \n",
    "    # total events in the session\n",
    "    session_events = df_.groupby('session_id')['session_id'].count()\n",
    "    \n",
    "    # getting labels\n",
    "    session_labels = (\n",
    "        labels_df\n",
    "        .loc[labels_df.question.isin(level_dict[level_group])]\n",
    "        .pivot(columns='question', values='correct', index='session')\n",
    "    )\n",
    "    \n",
    "    # final df pre labels\n",
    "    df_features = (\n",
    "        pd.concat([total_time_event, nunique_text_ids, nunique_fqid, event_counts, session_lengths, session_events, time_delta_mean], axis=1)\n",
    "    )\n",
    "    \n",
    "    # df with labels\n",
    "    df_final = (\n",
    "        pd.concat([df_features, session_labels], axis=1)\n",
    "        .reset_index()\n",
    "        .drop(columns=['session_id'])\n",
    "        .rename(columns={'index' : 'session_id'})\n",
    "    )\n",
    "    \n",
    "#     # extracting date and time data from the session_id\n",
    "#     df_final['year'] = df_final['session_id'].apply(lambda x: int(str(x)[:2]))\n",
    "#     df_final['month'] = df_final['session_id'].apply(lambda x: int(str(x)[2:4]))\n",
    "#     df_final['day'] = df_final['session_id'].apply(lambda x: int(str(x)[4:6]))\n",
    "#     df_final['hour'] = df_final['session_id'].apply(lambda x: int(str(x)[6:8]))\n",
    "\n",
    "#     # creating a weekend indicator because weekends are different\n",
    "#     df_final['weekend'] = np.where(df_final['day'].isin([6,0]), 1, 0)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c902f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a simple example to know what i'm doing\n",
    "group_k_fold = GroupKFold(n_splits=5)\n",
    "\n",
    "group1_data = get_data_for_level('5-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c528ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns that routinely added zero or negative value in prelim tests\n",
    "bad_cols = ['year', 'checkpoint', 'session_id', 'hour', 'day', \n",
    "            'weekend', 'fqid', 'notification_click', 'month', \n",
    "            'cutscene_click', 'observation_click']\n",
    "\n",
    "level_dict = {\n",
    "    '0-4' : [1, 2, 3],\n",
    "    '5-12' : [4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    "    '13-22' : [14, 15, 16, 17, 18]\n",
    "}\n",
    "\n",
    "# standardized feature columns to simplify\n",
    "feature_cols = [x for x in group1_data.columns if x not in level_dict['5-12']]\n",
    "feature_cols = [x for x in feature_cols if x not in bad_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "354b145e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6057502114576481 {'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 100}\n",
      "0.5137802285063735 {'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 150}\n",
      "0.5085908009510599 {'max_depth': 8, 'min_child_weight': 10, 'n_estimators': 150}\n",
      "0.6080037933764999 {'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 150}\n",
      "0.6151541414032232 {'max_depth': 3, 'min_child_weight': 10, 'n_estimators': 25}\n",
      "0.5710421940977841 {'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 150}\n",
      "0.5475278256378877 {'max_depth': 8, 'min_child_weight': 10, 'n_estimators': 150}\n",
      "0.5247914364711039 {'max_depth': 8, 'min_child_weight': 10, 'n_estimators': 150}\n",
      "0.5643293657787121 {'max_depth': 8, 'min_child_weight': 10, 'n_estimators': 100}\n",
      "0.6132823475036581 {'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 25}\n",
      "0.5472687031870742 {'max_depth': 8, 'min_child_weight': 5, 'n_estimators': 150}\n",
      "0.5029577936072773 {'max_depth': 8, 'min_child_weight': 5, 'n_estimators': 150}\n",
      "0.5540712537408627 {'max_depth': 6, 'min_child_weight': 10, 'n_estimators': 150}\n",
      "0.5587508024267238 {'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 150}\n",
      "0.6135824571180253 {'max_depth': 5, 'min_child_weight': 10, 'n_estimators': 25}\n",
      "0.4844779596706855 {'max_depth': 8, 'min_child_weight': 10, 'n_estimators': 150}\n",
      "0.4976688457435852 {'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 150}\n",
      "0.501013348285025 {'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# creating a df of the best params \n",
    "\n",
    "best_params_df = pd.DataFrame()\n",
    "\n",
    "for question in range(1, 19):\n",
    "    \n",
    "    if question in [1, 2, 3]:\n",
    "        df_ = get_data_for_level('0-4')\n",
    "    elif question in [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]:\n",
    "        df_ = get_data_for_level('5-12')\n",
    "    else:\n",
    "        df_ = get_data_for_level('13-22')\n",
    "    \n",
    "    fold = 1\n",
    "    \n",
    "    model = XGBClassifier()\n",
    "    cv_method = GroupKFold(n_splits=5)\n",
    "    \n",
    "    grid_params_ = {\n",
    "        'n_estimators' : [25, 100, 150],\n",
    "        'max_depth' : [3, 5, 6, 8],\n",
    "        'min_child_weight' : [1, 5, 10]\n",
    "    }\n",
    "    \n",
    "    X = df_[feature_cols]\n",
    "    X_groups = df_['session_id'].values\n",
    "    y = labels_df.loc[labels_df['question'] == question].set_index('session').loc[X_groups]['correct']\n",
    "    \n",
    "    \n",
    "    gridsearch = GridSearchCV(model,\n",
    "                              param_grid=grid_params_,\n",
    "                              cv=cv_method.split(X, y, groups=X_groups),\n",
    "                              scoring='f1_macro')    \n",
    "    gridsearch.fit(X, y)\n",
    "    \n",
    "    best_depth = gridsearch.best_params_['max_depth']\n",
    "    best_weight = gridsearch.best_params_['min_child_weight']\n",
    "    best_score = gridsearch.best_score_\n",
    "    best_estimators = gridsearch.best_params_['n_estimators']\n",
    "    \n",
    "    param_score_df_ = pd.DataFrame({\n",
    "        'question' : question,\n",
    "        'estimators' : best_estimators,\n",
    "        'best_depth' : best_depth,\n",
    "        'best_weight' : best_weight,\n",
    "        'best_score' : best_score},\n",
    "        index=[0]\n",
    "    )\n",
    "    \n",
    "    best_params_df = pd.concat([best_params_df, param_score_df_])\n",
    "    print(best_score, gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0de0438a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>estimators</th>\n",
       "      <th>best_depth</th>\n",
       "      <th>best_weight</th>\n",
       "      <th>best_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.605750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.513780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.508591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.615154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.547528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.524791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.564329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.613282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.547269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.502958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.554071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.558751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.613582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.484478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.501013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question  estimators  best_depth  best_weight  best_score\n",
       "0         1         100           6            5    0.605750\n",
       "0         2         150           3            5    0.513780\n",
       "0         3         150           8           10    0.508591\n",
       "0         4         150           6            1    0.608004\n",
       "0         5          25           3           10    0.615154\n",
       "0         6         150           6            1    0.571042\n",
       "0         7         150           8           10    0.547528\n",
       "0         8         150           8           10    0.524791\n",
       "0         9         100           8           10    0.564329\n",
       "0        10          25           3            5    0.613282\n",
       "0        11         150           8            5    0.547269\n",
       "0        12         150           8            5    0.502958\n",
       "0        13         150           6           10    0.554071\n",
       "0        14         150           5            5    0.558751\n",
       "0        15          25           5           10    0.613582\n",
       "0        16         150           8           10    0.484478\n",
       "0        17         150           8            1    0.497669\n",
       "0        18         100           5            5    0.501013"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f150fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_[feature_cols]\n",
    "X_groups = df_['session_id'].values\n",
    "y = labels_df.loc[labels_df['question'] == question].set_index('session').loc[X_groups]['correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f51a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "vals = []\n",
    "final_preds = []\n",
    "\n",
    "for question in range(1, 19):\n",
    "    \n",
    "    if question in [1, 2, 3]:\n",
    "        df_ = get_data_for_level('0-4')\n",
    "    elif question in [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]:\n",
    "        df_ = get_data_for_level('5-12')\n",
    "    else:\n",
    "        df_ = get_data_for_level('13-22')\n",
    "    \n",
    "    fold = 1\n",
    "    \n",
    "    for train, val in group_k_fold.split(X=df_, groups=df_['session_id']):\n",
    "\n",
    "        train_x = df_.iloc[train].copy()\n",
    "        train_sessions = train_x['session_id'].values\n",
    "        train_x = train_x[feature_cols].copy()\n",
    "        train_y = labels_df.loc[labels_df['question'] == question].set_index('session').loc[train_sessions]['correct']\n",
    "        \n",
    "        val_x = df_.iloc[val].copy()\n",
    "        val_sessions = val_x['session_id'].values\n",
    "        val_x = val_x[feature_cols]\n",
    "        val_y = labels_df.loc[labels_df['question'] == question].set_index('session').loc[val_sessions]['correct']\n",
    "\n",
    "        model = XGBClassifier(n_estimators=50)        \n",
    "        model.fit(train_x, train_y)\n",
    "        \n",
    "        preds = model.predict(val_x)\n",
    "        f1_score_ = f1_score(val_y, preds, average='macro')\n",
    "        \n",
    "        val_probs = model.predict_proba(val_x)[:,1]\n",
    "\n",
    "        best_threshold = None\n",
    "        best_f1 = 0.0\n",
    "\n",
    "        for threshold in np.arange(0.25, 0.88, 0.03):  \n",
    "            \n",
    "            # apply the threshold\n",
    "            val_preds = (val_probs > threshold).astype(int)\n",
    "\n",
    "            # get f1 score\n",
    "            f1 = f1_score(val_y, val_preds, average='macro')\n",
    "\n",
    "            # is it best? if so, change best\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        final_preds_ = (val_probs > best_threshold).astype(int)\n",
    "        \n",
    "        if fold == 4:\n",
    "            vals.append(val_y)\n",
    "            final_preds.append(final_preds_)            \n",
    "        \n",
    "        result_df_ = (pd.DataFrame(\n",
    "            {'question' : question,\n",
    "             'fold' : fold,\n",
    "             'default_f1': f1_score_,\n",
    "             'best_f1' : best_f1, \n",
    "             'best_threshold' : best_threshold},\n",
    "             index=[0]\n",
    "        )\n",
    "                    )\n",
    "                     \n",
    "        result_df = pd.concat([result_df, result_df_])\n",
    "        \n",
    "        print(\"Best Threshold:\", best_threshold)\n",
    "        print(\"Best F1 Score:\", best_f1)\n",
    "        \n",
    "        if fold == 4:\n",
    "            models[question] = [model, best_threshold]\n",
    "        \n",
    "        print(question, fold, f1_score_)\n",
    "        fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2a5ce682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>default_f1</th>\n",
       "      <th>best_f1</th>\n",
       "      <th>best_threshold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.599581</td>\n",
       "      <td>0.639871</td>\n",
       "      <td>0.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.498542</td>\n",
       "      <td>0.554962</td>\n",
       "      <td>0.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500269</td>\n",
       "      <td>0.574501</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.630844</td>\n",
       "      <td>0.666032</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.650578</td>\n",
       "      <td>0.654579</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.599032</td>\n",
       "      <td>0.641725</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.579858</td>\n",
       "      <td>0.629324</td>\n",
       "      <td>0.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.520727</td>\n",
       "      <td>0.557493</td>\n",
       "      <td>0.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.573295</td>\n",
       "      <td>0.627485</td>\n",
       "      <td>0.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.648769</td>\n",
       "      <td>0.650687</td>\n",
       "      <td>0.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.598989</td>\n",
       "      <td>0.627375</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500547</td>\n",
       "      <td>0.581074</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.564586</td>\n",
       "      <td>0.613536</td>\n",
       "      <td>0.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.556091</td>\n",
       "      <td>0.602486</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.619045</td>\n",
       "      <td>0.621210</td>\n",
       "      <td>0.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.457302</td>\n",
       "      <td>0.528288</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.466986</td>\n",
       "      <td>0.536314</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.498843</td>\n",
       "      <td>0.558268</td>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fold  default_f1   best_f1  best_threshold\n",
       "question                                            \n",
       "1          3.0    0.599581  0.639871           0.640\n",
       "2          3.0    0.498542  0.554962           0.844\n",
       "3          3.0    0.500269  0.574501           0.832\n",
       "4          3.0    0.630844  0.666032           0.694\n",
       "5          3.0    0.650578  0.654579           0.550\n",
       "6          3.0    0.599032  0.641725           0.718\n",
       "7          3.0    0.579858  0.629324           0.670\n",
       "8          3.0    0.520727  0.557493           0.592\n",
       "9          3.0    0.573295  0.627485           0.664\n",
       "10         3.0    0.648769  0.650687           0.502\n",
       "11         3.0    0.598989  0.627375           0.610\n",
       "12         3.0    0.500547  0.581074           0.778\n",
       "13         3.0    0.564586  0.613536           0.346\n",
       "14         3.0    0.556091  0.602486           0.652\n",
       "15         3.0    0.619045  0.621210           0.502\n",
       "16         3.0    0.457302  0.528288           0.688\n",
       "17         3.0    0.466986  0.536314           0.646\n",
       "18         3.0    0.498843  0.558268           0.838"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.groupby('question').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df=None):\n",
    "    \"how to prep the data for the kaggle notebook\"\n",
    "    \n",
    "    level_dict = {\n",
    "        '0-4' : [1, 2, 3],\n",
    "        '5-12' : [4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    "        '13-22' : [14, 15, 16, 17, 18]\n",
    "    }\n",
    "\n",
    "    \n",
    "    df_ = df.copy()\n",
    "    \n",
    "    # getting elapsed diffs\n",
    "    df_['event_time_delta'] = (\n",
    "        df_\n",
    "        .groupby('session_id')['elapsed_time']\n",
    "        .transform(lambda x: x.diff().fillna(x.min()))\n",
    "    )\n",
    "\n",
    "    # getting the time until the next event\n",
    "    df_['time_delta_til_next'] = (\n",
    "        df_\n",
    "        .groupby('session_id')['elapsed_time']\n",
    "        .transform(lambda x: abs(x.diff(-1)).fillna(abs(x.min())))\n",
    "    )\n",
    "    \n",
    "    # time delta means    \n",
    "    time_delta_mean = df_.groupby('session_id').agg(event_time_mean=('event_time_delta', 'mean'),\n",
    "                                                    event_time_std=('event_time_delta', 'std'),\n",
    "                                                    event_time_max=('event_time_delta', 'max'))\n",
    "    \n",
    "    # total time on each event\n",
    "    total_time_event = (\n",
    "        df_\n",
    "        .groupby(['session_id', 'event_name'])\n",
    "        .agg(total_time=('time_delta_til_next', 'sum'))\n",
    "        .unstack()\n",
    "    )   \n",
    "    \n",
    "    # unique text ids\n",
    "    nunique_text_ids = df_.groupby('session_id')['text_fqid'].nunique()\n",
    "    \n",
    "    # unique fqids \n",
    "    nunique_fqid = df_.groupby('session_id')['fqid'].nunique()\n",
    "    \n",
    "    # how many events of each type occurred in the session\n",
    "    event_counts = df_.groupby('session_id')['event_name'].value_counts().unstack()\n",
    "    \n",
    "    # getting session lengths\n",
    "    session_lengths = df_.groupby('session_id')['elapsed_time'].max().rename('total_length')\n",
    "    \n",
    "    # total events in the session\n",
    "    session_events = df_.groupby('session_id')['session_id'].count()\n",
    "    \n",
    "    # final df pre labels\n",
    "    df_features = (\n",
    "        pd.concat([total_time_event, nunique_text_ids, nunique_fqid, event_counts, session_lengths, session_events, time_delta_mean], axis=1)\n",
    "        .drop(columns='session_id')\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    df_features['year'] = df_features['session_id'].apply(lambda x: int(str(x)[:2]))\n",
    "    df_features['month'] = df_features['session_id'].apply(lambda x: int(str(x)[2:4]))\n",
    "    df_features['day'] = df_features['session_id'].apply(lambda x: int(str(x)[4:6]))\n",
    "    df_features['hour'] = df_features['session_id'].apply(lambda x: int(str(x)[6:8]))\n",
    "\n",
    "    # # creating a weekend indicator because weekends are different\n",
    "    df_features['weekend'] = np.where(df_features['day'].isin([6,0]), 1, 0)\n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving models\n",
    "for key in models.keys():\n",
    "    \n",
    "    model_ = models[key][0]\n",
    "    \n",
    "    with open(f'model_question_{key}.pickle', 'wb') as file:\n",
    "        pickle.dump(model_, file, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dae630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving thresholds - no reason to do this separately, TODO\n",
    "threshold_list = []\n",
    "\n",
    "for key in models.keys():\n",
    "    \n",
    "    threshold_ = models[key][1].round(2)\n",
    "    threshold_list.append(threshold_)\n",
    "    \n",
    "with open('threshold_list.pickle', 'wb') as file:\n",
    "    pickle.dump(threshold_list, file, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b3986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving features\n",
    "with open('feature_cols_may17.pickle', 'wb') as file:\n",
    "    pickle.dump(feature_cols, file, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a65e0450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# this cell iterates over the test data \n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# defining the questions for each group\n",
    "limits = {'0-4':(1,4), '5-12':(4,14), '13-22':(14,19)}\n",
    "\n",
    "for _, tf in test_df.groupby(['session_id', 'level_group']):\n",
    "    \n",
    "    # get the level group (to get the data for the model)\n",
    "    level_group = tf['level_group'].values[0]\n",
    "    \n",
    "    # create feature df\n",
    "    df_ = prep_data(tf)\n",
    "    \n",
    "    # figure out if feature columns are missing - important for submission\n",
    "    missing_columns = list(set(feature_cols) - set(df_.columns))\n",
    "    \n",
    "    # create a dataframe with the missing columns filled with 0s (for now)\n",
    "    missing_df = pd.DataFrame(0, columns=missing_columns, index=df_.index)\n",
    "    \n",
    "    # combine the original df and the missing df\n",
    "    df_ = pd.concat([df_, missing_df], axis=1)\n",
    "    \n",
    "    # get the questions to iterate over\n",
    "    a, b = limits[level_group]  \n",
    "    \n",
    "    for question in range(a, b):\n",
    "        # getting model and threshold for the question\n",
    "        model_ = models[question][0]\n",
    "        threshold = models[question][1]\n",
    "        \n",
    "        raw_pred_proba = model_.predict_proba(df_[feature_cols])[0, 1]\n",
    "        final_pred = (raw_pred_proba > threshold).astype(int)\n",
    "    \n",
    "    print(final_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
